





import getpass
import os

# 定义一个帮助函数来检查环境变量，如果不存在则提示用户输入
def _set_if_undefined(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"请输入您的 {var}")

# 设置 OpenAI 和 Langchain API 密钥
# _set_if_undefined("OPENAI_API_KEY")
# _set_if_undefined("LANGCHAIN_API_KEY")
# _set_if_undefined("TAVILY_API_KEY")






# 在 LangSmith 中添加追踪功能
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "Reflection"





from langchain_core.messages import AIMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
# from langchain_openai import ChatOpenAI
from langchain_ollama.chat_models import ChatOllama





multi_task_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a versatile assistant capable of handling various tasks such as writing articles, coding, and report writing. Based on the user's request, your task is to create high-quality output tailored to the specific context:"
            "\n\n1. **For article writing**: Focus on crafting well-structured, coherent, and engaging articles. Pay attention to clarity, flow, and readability to ensure the content is compelling and easy to understand."
            "\n- Respond to user feedback by refining the tone, style, and structure of the article."
            "\n- **After revisions, always provide the complete, updated article, not just the changes.**"
            "\n\n2. **For coding tasks**: Prioritize writing clean, efficient, and well-documented code. Ensure best practices are followed, and the code is optimized for performance and scalability."
            "\n- Revise the **entire code** based on user feedback to improve functionality and efficiency."
            "\n- Include code comments and explanations in Chinese."
            "\n- **After revisions, always provide the complete, updated code, not just the changes.**"
            "\n\n3. **For report writing**: Create structured, formal, and clear reports that effectively present information in a logical manner. Pay close attention to detail and professionalism to ensure the report meets high standards."
            "\n- Adjust the report's format, depth, and clarity in response to user feedback."
            "\n- **After revisions, always provide the complete, updated report, not just the changes.**"
            "\n- Output the report contents in Chinese.",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)




writer = multi_task_prompt | ChatOllama(
    # model="llama3.1:8b-instruct-q8_0",
    model="llama3.1:8b-instruct-q4_0",# 更换模型
    max_tokens=8192,
    temperature=1.2,
)





article = ""

topic_article = HumanMessage(
    content="参考水浒传的风格，改写吴承恩的西游记中任意篇章，比如孙悟空大战白骨精"
)

for chunk in writer.stream({"messages": [topic_article]}):
    print(chunk.content, end="")
    article += chunk.content





code = ""

topic_code = HumanMessage(
    content="请编写一段Python代码，该代码实现一个简单的计算器，能够处理加法、减法、乘法和除法操作。"
)

for chunk in writer.stream({"messages": [topic_code]}):
    print(chunk.content, end="")
    code += chunk.content





report = ""

topic_report = HumanMessage(
    content="请撰写一篇关于智算中心的报告，重点介绍其定义、核心技术、应用场景以及未来发展趋势。要求报告内容结构清晰、技术细节准确，并结合实际案例进行分析。"
)

for chunk in writer.stream({"messages": [topic_report]}):
    print(chunk.content, end="")
    report += chunk.content



from IPython.display import Markdown, display

# 使用Markdown显示优化后的格式

display(Markdown("**--------------------------【写文章】--------------------------：**\n\n" + article))

display(Markdown("**--------------------------【写代码】--------------------------：**\n\n```python\n" + code + "\n```"))

display(Markdown("**--------------------------【写报告】--------------------------：**\n\n" + report))














reflection_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a versatile reviewer responsible for providing constructive critiques and actionable improvement suggestions based on the user's submission. Do not generate or rewrite any content; only provide feedback."
            "\n\n1. **For article submissions**: Evaluate the submission based on the following criteria:"
            "\n- **Content**: Is the topic clear and is the information accurate?"
            "\n- **Structure**: Does the article have a clear introduction, body, and conclusion?"
            "\n- **Language Expression**: Are the word choices appropriate? Are there any grammar or spelling errors?"
            "\n- **Style and Tone**: Is the writing style suitable for the intended audience?"
            "\nOrganize your feedback under the following sections:"
            "\n- **Strengths**: Highlight the positive aspects of the article."
            "\n- **Weaknesses**: Point out areas that need improvement."
            "\n- **Suggestions for Improvement**: Provide specific, actionable recommendations."
            "\nDo not generate new content."
            "\n\n2. **For code submissions**: Evaluate based on the following criteria:"
            "\n- **Functionality**: Does the code correctly implement the intended functionality?"
            "\n- **Code Structure**: Is the code well-organized and modular?"
            "\n- **Readability**: Do variable names, comments, and code style aid understanding?"
            "\n- **Performance Optimization**: Is the code efficient? Is there room for optimization?"
            "\n- **Best Practices**: Does it follow programming language best practices?"
            "\nOrganize your feedback under the following sections:"
            "\n- **Strengths**: Point out what the code does well."
            "\n- **Weaknesses**: Note any issues or areas for improvement."
            "\n- **Suggestions for Improvement**: Offer specific advice to enhance code quality."
            "\nDo not provide or rewrite any code."
            "\n\n3. **For report submissions**: Evaluate based on the following criteria:"
            "\n- **Logical Flow**: Is the information presented in a logical order?"
            "\n- **Clarity**: Are the points and data clearly understandable?"
            "\n- **Depth and Detail**: Is the content sufficient? Does it support the conclusions?"
            "\n- **Professionalism**: Does the format, tone, and detail meet professional standards?"
            "\nOrganize your feedback under the following sections:"
            "\n- **Strengths**: Highlight the strong points of the report."
            "\n- **Weaknesses**: Identify aspects that need improvement."
            "\n- **Suggestions for Improvement**: Provide actionable recommendations."
            "\nDo not create new sections or content."
            "\n\nIn all cases, ensure your feedback is specific, detailed, and aimed only at improving the quality of the submission. Do not generate any new content."
            "\n\nRemember to respond in Chinese.",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)





reflect = reflection_prompt | ChatOllama(
    # model="llama3.1:8b-instruct-q8_0",
    model="llama3.1:8b-instruct-q4_0",
    max_tokens=8192,
    temperature=0.2,
)





reflection_article= ""

# 将主题（topic）和生成的文章（article）作为输入发送给反思智能体
for chunk in reflect.stream({"messages": [topic_article, HumanMessage(content=article)]}):
    print(chunk.content, end="")
    reflection_article+= chunk.content





reflection_code = ""
for chunk in reflect.stream({"messages": [topic_code, HumanMessage(content=code)]}):
    print(chunk.content, end="")
    reflection_code+= chunk.content





reflection_report = ""
for chunk in reflect.stream({"messages": [topic_report, HumanMessage(content=report)]}):
    print(chunk.content, end="")
    reflection_report+= chunk.content


from IPython.display import Markdown, display

# 使用Markdown显示优化后的格式
display(Markdown("**--------------------------【文章点评】--------------------------：**\n\n" + reflection_article))

display(Markdown("**--------------------------【代码点评】--------------------------：**\n\n```python\n" + reflection_code + "\n```"))

display(Markdown("**--------------------------【报告点评】--------------------------：**\n\n" + reflection_report))


from typing import Annotated  # 用于类型注解
from langgraph.graph import END, StateGraph, START  # 导入状态图的相关常量和类
from langgraph.graph.message import add_messages  # 用于在状态中处理消息
from langgraph.checkpoint.memory import MemorySaver  # 内存保存机制，用于保存检查点
from typing_extensions import TypedDict  # 用于定义带有键值对的字典类型

# 定义状态类，使用TypedDict以保存消息
class State(TypedDict):
    messages: Annotated[list, add_messages]  # 使用注解确保消息列表使用add_messages方法处理

# 异步生成节点函数：生成内容（如作文）
# 输入状态，输出包含新生成消息的状态
async def generation_node(state: State) -> State:
    # 调用生成器(writer)，并将消息存储到新的状态中返回
    return {"messages": [await writer.ainvoke(state['messages'])]}

# 异步反思节点函数：对生成的内容进行反思和反馈
# 输入状态，输出带有反思反馈的状态
async def reflection_node(state: State) -> State:
    # 创建一个消息类型映射，ai消息映射为HumanMessage，human消息映射为AIMessage
    cls_map = {"ai": HumanMessage, "human": AIMessage}
    
    # 处理消息，保持用户的原始请求（第一个消息），转换其余消息的类型
    translated = [state['messages'][0]] + [
        cls_map[msg.type](content=msg.content) for msg in state['messages'][1:]
    ]
    
    # 调用反思器(reflect)，将转换后的消息传入，获取反思结果
    res = await reflect.ainvoke(translated)
    
    # 返回新的状态，其中包含反思后的消息
    return {"messages": [HumanMessage(content=res.content)]}



MAX_ROUND = 6

# 定义条件函数，决定是否继续反思过程
# 如果消息数量超过6条，则终止流程
def should_continue(state: State):
    if len(state["messages"]) > MAX_ROUND:
        return END  # 达到条件时，流程结束
    return "reflect"  # 否则继续进入反思节点


# 创建状态图，传入初始状态结构
builder = StateGraph(State)

# 在状态图中添加"writer"节点，节点负责生成内容
builder.add_node("writer", generation_node)

# 在状态图中添加"reflect"节点，节点负责生成反思反馈
builder.add_node("reflect", reflection_node)

# 定义起始状态到"writer"节点的边，从起点开始调用生成器
builder.add_edge(START, "writer")


# 在"writer"节点和"reflect"节点之间添加条件边
# 判断是否需要继续反思，或者结束
builder.add_conditional_edges("writer", should_continue)

# 添加从"reflect"节点回到"writer"节点的边，进行反复的生成-反思循环
builder.add_edge("reflect", "writer")

# 创建内存保存机制，允许在流程中保存中间状态和检查点
memory = MemorySaver()

# 编译状态图，使用检查点机制
graph = builder.compile(checkpointer=memory)





# 可视化图
from IPython.display import Image, display

try:
    display(
        Image(
            graph.get_graph(xray=True).draw_mermaid_png()
        )
    )
except Exception as e:
    print(f"Error generating graph: {e}")





from IPython.display import Markdown, display

class StepTracker:
    def __init__(self):
        self.step_counter = 0  # 初始化计数器

    def pretty_print_event_markdown(self, event):
        # 增加计数器
        self.step_counter += 1
        # 在函数调用之前打印 step
        display(Markdown(f"## Round {self.step_counter}"))

        # 如果是生成写作部分
        if 'writer' in event:
            generate_md = "#### 任务生成:\n"
            for message in event['writer']['messages']:
                generate_md += f"- {message.content}\n"
            display(Markdown(generate_md))

        # 如果是反思评论部分
        if 'reflect' in event:
            reflect_md = "#### 评论反思:\n"
            for message in event['reflect']['messages']:
                reflect_md += f"- {message.content}\n"
            display(Markdown(reflect_md))









inputs_article = {
    "messages": [
        HumanMessage(content="参考西游记唐僧的说话风格，写一篇奉劝年轻人努力工作的文章")
    ],
}

config = {"configurable": {"thread_id": "1"}}

# 实例化新的 StepTracker
step_tracker_article = StepTracker()

async for event in graph.astream(inputs_article, config):
    step_tracker_article.pretty_print_event_markdown(event)






inputs_code = {
    "messages": [
        HumanMessage(content="请编写一段Python代码，该代码实现一个简单的计算器，能够处理加法、减法、乘法和除法操作。")
    ],
}

config = {"configurable": {"thread_id": "2"}}

# 实例化新的 StepTracker
step_tracker_code = StepTracker()

async for event in graph.astream(inputs_code, config):
    step_tracker_code.pretty_print_event_markdown(event)






inputs_report = {
    "messages": [
        HumanMessage(content="请撰写一篇关于智算中心的报告，重点介绍其定义、核心技术、应用场景以及未来发展趋势。要求报告内容结构清晰、技术细节准确，并结合实际案例进行分析。")
    ],
}

config = {"configurable": {"thread_id": "3"}}

# 实例化新的 StepTracker
step_tracker_report = StepTracker()

async for event in graph.astream(inputs_report, config):
    step_tracker_report.pretty_print_event_markdown(event)







