{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0cac58c-71e5-4905-a920-08e5e3ba1ea1",
   "metadata": {},
   "source": [
    "## **Homework**\n",
    "**1. 使用不同的大模型运行多智能体，对比结果并评选 `gpt-4o` 之下最好的大模型，将所有的大模型和最终结果生成一张表格；**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ba2a7-b9eb-4952-bf13-2e09ebecdb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# 定义一个帮助函数来检查环境变量，如果不存在则提示用户输入\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"请输入您的 {var}\")\n",
    "\n",
    "# 设置 OpenAI 和 Langchain API 密钥\n",
    "# _set_if_undefined(\"OPENAI_API_KEY\")\n",
    "# _set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "# _set_if_undefined(\"TAVILY_API_KEY\")\n",
    "\n",
    "# 可选：在 LangSmith 中添加追踪功能\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Multi-agent Collaboration\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad906e-bab3-4164-ad44-d49a80dc03f6",
   "metadata": {},
   "source": [
    "### **1.辅助函数：创建智能体**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea8e3da-38a9-4ffb-b8fc-01250889630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "\n",
    "# 创建智能体的函数，绑定 LLM（大型语言模型） 和工具\n",
    "def create_agent(llm, tools, system_message: str):\n",
    "    \"\"\"创建一个智能体。\"\"\"\n",
    "    # 定义智能体的提示模板，包含系统消息和工具信息\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "                \" Use the provided tools to progress towards answering the question.\"\n",
    "                \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "                \" will help where you left off. Execute what you can to make progress.\"\n",
    "                \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "                \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "                \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),  # 用于替换的消息占位符\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 将系统消息部分和工具名称插入到提示模板中\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    \n",
    "    # 将提示模板与语言模型和工具绑定\n",
    "    return prompt | llm.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350b8ba2-5910-4414-9554-093950f0e062",
   "metadata": {},
   "source": [
    "### **2.定义工具**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c2c0c-c5de-4113-9120-17079e58e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "# Tavily 搜索工具，用于搜索最多 5 条结果\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "# Python REPL 工具，用于执行 Python 代码\n",
    "repl = PythonREPL()\n",
    "\n",
    "@tool\n",
    "def python_repl(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "\n",
    "    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "\n",
    "    return (\n",
    "        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25b6638-1467-4089-a29d-43ec1e3baf33",
   "metadata": {},
   "source": [
    "### **3.辅助函数：智能体节点**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e4ffb-01df-492d-80ef-1cc4e2d33d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 辅助函数：为智能体创建一个节点\n",
    "def agent_node(state, agent, name):\n",
    "    # 调用智能体，获取结果\n",
    "    result = agent.invoke(state)\n",
    "    \n",
    "    # 将智能体的输出转换为适合追加到全局状态的格式\n",
    "    if isinstance(result, ToolMessage):\n",
    "        pass  # 如果是工具消息，跳过处理\n",
    "    else:\n",
    "        # 将结果转换为 AIMessage，并排除部分字段\n",
    "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    \n",
    "    # 返回更新后的状态，包括消息和发送者\n",
    "    return {\n",
    "        \"messages\": [result],  # 包含新生成的消息\n",
    "        # 我们使用严格的工作流程，通过记录发送者来知道接下来传递给谁\n",
    "        \"sender\": name,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df6a1c0-de3d-403b-93a5-9d8bbdbfa9e4",
   "metadata": {},
   "source": [
    "### **为 Agent 配置各自的大模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf058e8-6d31-4f0a-b490-4289cae43b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "research_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "chart_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99817a90-b932-4200-9a3a-f1b77a557d69",
   "metadata": {},
   "source": [
    "### **4. 定义 研究智能体及其节点**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0bcd59-5949-4345-9414-508e2a25d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 研究智能体及其节点\n",
    "research_agent = create_agent(\n",
    "    research_llm,  # 使用 research_llm 作为研究智能体的语言模型\n",
    "    [tavily_tool],  # 研究智能体使用 Tavily 搜索工具\n",
    "    system_message=\"Before using the search engine, carefully think through and clarify the query. \"\n",
    "    \"Then, conduct a single search that addresses all aspects of the query in one go.\",  # 系统消息，指导智能体如何使用搜索工具\n",
    ")\n",
    "\n",
    "# 使用 functools.partial 创建研究智能体的节点，指定该节点的名称为 \"Researcher\"\n",
    "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aebba0-d159-4cf7-9ee5-c00a69c102d0",
   "metadata": {},
   "source": [
    "### **5. 定义 图表生成器智能体及其节点**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefa782-2692-4580-9a90-7af59fa6b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_agent = create_agent(\n",
    "    chart_llm,  # 使用 chart_llm 作为图表生成器智能体的语言模型\n",
    "    [python_repl],  # 图表生成器智能体使用 Python REPL 工具\n",
    "    system_message=\"Create clear and user-friendly charts based on the provided data.\",  # 系统消息，指导智能体如何生成图表\n",
    ")\n",
    "\n",
    "# 使用 functools.partial 创建图表生成器智能体的节点，指定该节点的名称为 \"Chart Generator\"\n",
    "chart_node = functools.partial(agent_node, agent=chart_agent, name=\"Chart Generator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b38fcae-6bfe-4bf5-a136-e809621a0674",
   "metadata": {},
   "source": [
    "### **6. 导入预构建的工具节点**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213a89fd-adbe-4f56-bed1-00aeca646312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# 定义工具列表，包括 Tavily 搜索工具和 Python REPL 工具\n",
    "tools = [tavily_tool, python_repl]\n",
    "\n",
    "# 创建工具节点，负责工具的调用\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f643c3d-0ffe-4f00-9502-1c2999da418c",
   "metadata": {},
   "source": [
    "### **7. 建立智能体节点间通信 AgentState**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a51a3d-6ca7-4615-80e8-ddfedbda22f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "# 定义图中传递的对象，包含消息和发送者信息\n",
    "class AgentState(TypedDict):\n",
    "    # messages 是传递的消息，使用 Annotated 和 Sequence 来标记类型\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # sender 是发送消息的智能体\n",
    "    sender: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d49f26-3bcc-4c19-8493-6af39f4364fe",
   "metadata": {},
   "source": [
    "### **8. 定义工作流（状态图）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd26a30-f411-4a25-9be8-c8576f85fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个状态图 workflow，使用 AgentState 来管理状态\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 将研究智能体节点、图表生成器智能体节点和工具节点添加到状态图中\n",
    "workflow.add_node(\"Researcher\", research_node)\n",
    "workflow.add_node(\"Chart Generator\", chart_node)\n",
    "workflow.add_node(\"call_tool\", tool_node)\n",
    "\n",
    "# 定义路由函数\n",
    "from typing import Literal\n",
    "\n",
    "# 路由器函数，用于决定下一步是执行工具还是结束任务\n",
    "def router(state) -> Literal[\"call_tool\", \"__end__\", \"continue\"]:\n",
    "    messages = state[\"messages\"]  # 获取当前状态中的消息列表\n",
    "    last_message = messages[-1]  # 获取最新的一条消息\n",
    "    \n",
    "    # 如果最新消息包含工具调用，则返回 \"call_tool\"，指示执行工具\n",
    "    if last_message.tool_calls:\n",
    "        return \"call_tool\"\n",
    "    \n",
    "    # 如果最新消息中包含 \"FINAL ANSWER\"，表示任务已完成，返回 \"__end__\" 结束工作流\n",
    "    if \"FINAL ANSWER\" in last_message.content:\n",
    "        return \"__end__\"\n",
    "    \n",
    "    # 如果既没有工具调用也没有完成任务，继续流程，返回 \"continue\"\n",
    "    return \"continue\"\n",
    "\n",
    "# 定义条件边逻辑\n",
    "# 为 \"Researcher\" 智能体节点添加条件边，根据 router 函数的返回值进行分支\n",
    "workflow.add_conditional_edges(\n",
    "    \"Researcher\",\n",
    "    router,  # 路由器函数决定下一步\n",
    "    {\n",
    "        \"continue\": \"Chart Generator\",  # 如果 router 返回 \"continue\"，则传递到 Chart Generator\n",
    "        \"call_tool\": \"call_tool\",  # 如果 router 返回 \"call_tool\"，则调用工具\n",
    "        \"__end__\": END  # 如果 router 返回 \"__end__\"，则结束工作流\n",
    "    },\n",
    ")\n",
    "\n",
    "# 为 \"Chart Generator\" 智能体节点添加条件边\n",
    "workflow.add_conditional_edges(\n",
    "    \"Chart Generator\",\n",
    "    router,  # 同样使用 router 函数决定下一步\n",
    "    {\n",
    "        \"continue\": \"Researcher\",  # 如果 router 返回 \"continue\"，则回到 Researcher\n",
    "        \"call_tool\": \"call_tool\",  # 如果 router 返回 \"call_tool\"，则调用工具\n",
    "        \"__end__\": END  # 如果 router 返回 \"__end__\"，则结束工作流\n",
    "    },\n",
    ")\n",
    "\n",
    "# 为 \"call_tool\" 工具节点添加条件边，基于“sender”字段决定下一个节点\n",
    "# 工具调用节点不更新 sender 字段，这意味着边将返回给调用工具的智能体\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_tool\",\n",
    "    lambda x: x[\"sender\"],  # 根据 sender 字段判断调用工具的是哪个智能体\n",
    "    {\n",
    "        \"Researcher\": \"Researcher\",  # 如果 sender 是 Researcher，则返回给 Researcher\n",
    "        \"Chart Generator\": \"Chart Generator\",  # 如果 sender 是 Chart Generator，则返回给 Chart Generator\n",
    "    },\n",
    ")\n",
    "\n",
    "# 添加开始节点，将流程从 START 节点连接到 Researcher 节点\n",
    "workflow.add_edge(START, \"Researcher\")\n",
    "\n",
    "# 编译状态图以便后续使用\n",
    "graph = workflow.compile()\n",
    "\n",
    "# 可视化图\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(\n",
    "        Image(\n",
    "            graph.get_graph(xray=True).draw_mermaid_png()\n",
    "        )\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error generating graph: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a30ee-b87b-4eec-8022-d5a52e0b2971",
   "metadata": {},
   "source": [
    "### **9. 执行工作流**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b7c8ef-daa2-47d3-b662-cfd36fce6c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Obtain the GDP of the United States from 2000 to 2020, \"\n",
    "            \"and then plot a line chart with Python. End the task after generating the chart。\"\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    # 设置最大递归限制\n",
    "    {\"recursion_limit\": 20},\n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()  # 打印消息内容\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
